{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Hypothesis for Python\n",
    "\n",
    "Hypothesis is a powerful and easy-to-use library for property-based testing in Python. This guide is written with the assumption that the reader is new to property-based testing.\n",
    "\n",
    "## What is Property-Based Testing?\n",
    "\n",
    "Property-based testing in its simplest form is used to test a program or properties of a program against a wide range of inputs. This is in contrast to traditional software testing where using a specific input is tested. The exact details may vary on how the wide range of input is generated, but the main outcome is the same - a more robust way to test software. With that said, traditional software testing still has its place and should be used in conjunction with property-based testing. \n",
    "\n",
    "## Advantages and Disadvantages of Hypothesis\n",
    "\n",
    "It is important to be aware of the advantages of disadvantages of Hypothesis in order to make an informed decision about whether or not to incorporate it.\n",
    "\n",
    "### Advantages\n",
    "1. **Finds Edge Cases and Hidden Bugs**: Seeing as the test cases are randomly generated, it might help to find bugs and edge cases that were not thought of during traditional testing.\n",
    "2. **Time Efficiency**: Hypothesis is easy to implement and automatic test generation saves time.\n",
    "3. **Improves Test Robustness**: Due to a wide range of inputs, testing is more robust.\n",
    "4. **Easy to Integrate**: Hypothesis is easy to integrate into an existing Python project.\n",
    "\n",
    "### Disadvantages\n",
    "1. **Longer Execution Time**: Tests in Hypothesis can take longer to run compared to a traditional unit test suite because it generates and runs many more test cases.\n",
    "2. **Less Control Over Test Cases**: Whereas as traditional testing is precise, property-based testing using hypothesis is less precise and even has a random element to it.\n",
    "3. **Reproducibility**: Although Hypothesis does its best to narrow down inputs that caused the error, due to the random element this is not always that straightforward and as precise with traditional software testing.\n",
    "\n",
    "## How to Use Hypothesis\n",
    "\n",
    "This section focusses on the actual usage of hypothesis with a very simple guide.\n",
    "\n",
    "### Setting Up\n",
    "\n",
    "This setup has been tested with the following specifications:\n",
    "- Ubuntu 22.04.3 LTS\n",
    "- Python 3.10.12\n",
    "- pip 22.0.2 \n",
    "- Hypothesis 6.92.2\n",
    "\n",
    "However, assuming the latest version of Python and pip are installed, Hypothesis and pytest should work. \n",
    "\n",
    "\n",
    "To install Hypothesis and pytest, run:\n",
    "\n",
    "```bash\n",
    "pip install hypothesis pytest\n",
    "```\n",
    "\n",
    "### Basic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypothesis import given\n",
    "import hypothesis.strategies as st\n",
    "\n",
    "@given(st.integers())\n",
    "def test_builtin_abs(x: int) -> None:\n",
    "    assert abs(x) >= 0\n",
    "    assert abs(x) == (x if x >= 0 else -x)\n",
    "\n",
    "test_builtin_abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function tests the built-in absolute value function of the Python programming language. An absolute value takes a given integer and returns the same integer if the integer is greater or equal to 0, otherwise it inverts the negative sign if the integer is negative returning a positive or absolute number.\n",
    "\n",
    "**The Purpose of the `given` Decorator**\n",
    "- The `given` decorator is used to **specify the inputs** to the function you would like to test.\n",
    "- Uses specified **strategies**\n",
    "\n",
    "**Strategies in Hypothesis**\n",
    "- Defines how input should be generated\n",
    "- For instance, `st.integers` will generate integers across the range of valid Python integers\n",
    "- Other options are `st.text` to generate text and `st.date` to generate dates. One can even create complex types\n",
    "- Can be further narrowed down, i.e. by specifying ranges for the numbers generated by st.integers()\n",
    "- Can be thought of as property. By specifying `st.integers` we are asserting that the program should pass the test for all valid integers\n",
    "\n",
    "\n",
    "### Multiple Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_strings(a:str, b:str) -> str:\n",
    "    if not isinstance(a, str) or not isinstance(b, str):\n",
    "        raise TypeError(\"Inputs must be of type string\")\n",
    "\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@given(st.text(), st.text())\n",
    "def test_concat_strings(a: str, b: str) -> None:\n",
    "    result = concat_strings(a, b)\n",
    "    assert result == a + b\n",
    "    assert len(result) == len(a) + len(b)\n",
    "\n",
    "test_concat_strings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see in the above example, using hypothesis with multiple inputs is as easy as matching the inputs of the given decorator to the types of the function one would like to test.\n",
    "\n",
    "### Complex Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypothesis.strategies import composite\n",
    "\n",
    "PI = 3.14159\n",
    "\n",
    "@composite\n",
    "def custom_input_generator(draw) -> tuple[float, str]:\n",
    "    decimal = draw(st.floats(max_value=PI))\n",
    "    text = draw(st.text(alphabet=st.characters(whitelist_categories=['Lu']), min_size=2, max_size=5))\n",
    "    return decimal, text\n",
    "\n",
    "@given(custom_input_generator())\n",
    "def test_custom_input_generator(generated_input: tuple[float, str]) -> None:\n",
    "    decimal, text = generated_input\n",
    "    assert decimal <= PI\n",
    "    assert len(text) >= 2 and len(text) <= 5\n",
    "    assert text.isupper()\n",
    "\n",
    "test_custom_input_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**The Purpose of the `composite` Decorator**\n",
    "- The composite decorator is used to combine input test generation methods (**_search strategies_**) into a single, more powerful and complex version.\n",
    "\n",
    "**Arguments to _Search Strategies_**\n",
    "- Search strategies can receive arguments to further refine inputs generated\n",
    "- For instance, `st.floats(max_value=PI)` means all floats generated will be smaller or equal to PI\n",
    "- And `alphabet=st.characters(whitelist_categories=['Lu'])` means all the text generated will be uppercase letters\n",
    "- Search strategy arguments can also be used outside of the composite decorator\n",
    "- Alternatively, lambda functions can be used such as `st.integers().filter(lambda x: x != 0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying Test Case Amount\n",
    "\n",
    "To enhance the robustness of tests, increasing the quantity of generated tests can be beneficial. Additionally, creating a substantial volume of random test cases will help to approximate formal verification. The quantity of generated test cases can be modified using the `settings` decorator and the `max_samples` property:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypothesis import settings\n",
    "\n",
    "@settings(max_examples=100)\n",
    "@given(st.integers())\n",
    "def test_builtin_abs(x: int) -> None:\n",
    "    assert abs(x) >= 0\n",
    "    assert abs(x) == (x if x >= 0 else -x)\n",
    "\n",
    "test_builtin_abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be done globally, by specifying the following at the beginning of the test file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.register_profile(\"default\", max_examples=100)\n",
    "settings.load_profile(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying Seeds\n",
    "\n",
    "A noteworthy capability of Hypothesis is the ability to specify a seed. By specifying a seed, the test cases that are produced by Hypothesis remain consistent across runs, thus removing randomness. This feature is particularly useful for debugging, as Hypothesis tries to identify and display the exact seed that triggered a failure in the program. Incorporating specific seeds into the test suite, in addition to randomized tests, can enhance test reliability. To set a seed, use the `seed` decorator with a seed value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypothesis import given\n",
    "from hypothesis import seed\n",
    "import hypothesis.strategies as st\n",
    "\n",
    "@seed(30)\n",
    "@given(st.integers())\n",
    "def test_builtin_abs(x: int) -> None:\n",
    "    assert abs(x) >= 0\n",
    "    assert abs(x) == (x if x >= 0 else -x)\n",
    "\n",
    "test_builtin_abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration with pytest\n",
    "\n",
    "To integrate Hypothesis with pytest is extremely easy, simply run: \n",
    "\n",
    "```bash\n",
    "pytest\n",
    "```\n",
    "\n",
    "Like one normally would. Either in the correct directory or by explicitly stating the file.\n",
    "\n",
    "It should automatically pick up and run the Hypothesis tests. In addition to the Hypothesis tests, one can also have normal unit and integration tests. This can be demonstrated as follows:\n",
    "\n",
    "1. Writing a hypothesis test to a Python file\n",
    "2. Running the file with pytest\n",
    "3. Deleting the file\n",
    "\n",
    "For an example, the following three code blocks can be run in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_script.py\n",
    "from hypothesis import given\n",
    "import hypothesis.strategies as st\n",
    "\n",
    "@given(st.integers())\n",
    "def test_builtin_abs(x: int) -> None:\n",
    "    assert abs(x) >= 0\n",
    "    assert abs(x) == (x if x >= 0 else -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                        [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.09s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -q test_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although multiple test cases were run, pytest only shows that a single test case has been pased. For more output, specifically relevant to Hypothesis, the following command can be run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                        [100%]\u001b[0m\n",
      "============================ Hypothesis Statistics =============================\n",
      "test_script.py::test_builtin_abs:\n",
      "\n",
      "  - during reuse phase (0.00 seconds):\n",
      "    - Typical runtimes: < 1ms, of which < 1ms in data generation\n",
      "    - 1 passing examples, 0 failing examples, 0 invalid examples\n",
      "\n",
      "  - during generate phase (0.03 seconds):\n",
      "    - Typical runtimes: < 1ms, of which < 1ms in data generation\n",
      "    - 99 passing examples, 0 failing examples, 0 invalid examples\n",
      "\n",
      "  - Stopped because settings.max_examples=100\n",
      "\n",
      "\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -q test_script.py --hypothesis-show-statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(\"test_script.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As seen in the examples above, Hypothesis is easy to use and allows for the creation of complex logic in the generation of inputs used. Thus it is a great addition to the testing setup of any software project.\n",
    "\n",
    "## References\n",
    "\n",
    "This guide is primarly based on the following resource:\n",
    "\n",
    "Hypothesis Development Team. \"Hypothesis for Python.\" Hypothesis, Hypothesis Development Team, n.d., https://hypothesis.readthedocs.io. Accessed December 20, 2023."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
