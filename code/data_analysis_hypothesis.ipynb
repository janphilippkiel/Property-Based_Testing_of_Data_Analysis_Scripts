{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating Hypothesis into a Data Analysis Script\n",
    "\n",
    "In this notebook, the hypothesis library will be used to test a data analysis script. The script is an astronaut analysis script provided by the German Aerospace Center (DLR). More, specific information is available in the reference section.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This script builds upon the knowledge from the `tutorial.ipynb` script. That is, some base knowledge regarding Property-Based Testing and the hypothesis python library is assumed. It is also assumed that the latest version of hypothesis (at the time of writing) is correctly installed. And then there are packages related to the data analysis script. In brief, assuming the latest versions of Python and Pip are installed, hypothesis and the required packages can be installed using: \n",
    "\n",
    "```\n",
    "pip install hypothesis pandas\n",
    "```\n",
    "\n",
    "## Code Examples of using Hypothesis to test the Data Analysis Script \n",
    "\n",
    "### Example 1 - Calculate Age\n",
    "\n",
    "The first example will be a simpler example, showcasing an easy and quick to understand application of hypothesis in a data analysis script. A simple function, `calculate_age()` will be tested. This is part of a larger and more complex function `prepare_data_set()` which will be tested in the next example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "from hypothesis import given, strategies as st\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "def calculate_age(born):\n",
    "    today = date.today()\n",
    "    return today.year - born.year - ((today.month, today.day) < (born.month, born.day))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function uses the birth year and the current year to calculate an age. It also accounts for a birthday has not yet occurred in the current year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@given(st.dates(min_value=date(1920, 1, 1), \n",
    "                                max_value=date.today()))\n",
    "def test_calculate_age(born):\n",
    "    age = calculate_age(born)\n",
    "    assert age >= 0 and age <= (born.today().year - born.year)\n",
    "\n",
    "test_calculate_age()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test function uses hypothesis to input random dates between the year 1920 and the current year and then asserts that the age is non-negative as well as within a reasonable range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 - Prepare Data Set\n",
    "\n",
    "Arguably one of the most important functions, `prepare_data_set()` will be tested in this example. \n",
    "\n",
    "Here is the code from the script. Please note, that the line `df[\"time_in_space_D\"] = df[\"time_in_space\"].astype(\"timedelta64[D]\")` has been altered to `df[\"time_in_space\"] / pd.Timedelta(days=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_set(df):\n",
    "    df = rename_columns(df)\n",
    "    df = df.set_index(\"astronaut_id\")\n",
    "\n",
    "    # Set pandas dtypes for columns with date or time\n",
    "    df = df.dropna(subset=[\"time_in_space\"])\n",
    "    df[\"time_in_space\"] = df[\"time_in_space\"].astype(int)\n",
    "    df[\"time_in_space\"] = pd.to_timedelta(df[\"time_in_space\"], unit=\"m\")\n",
    "    df[\"birthdate\"] = pd.to_datetime(df[\"birthdate\"])\n",
    "    df[\"date_of_death\"] = pd.to_datetime(df[\"date_of_death\"])\n",
    "    df.sort_values(\"birthdate\", inplace=True)\n",
    "\n",
    "    # Calculate extra columns from the original data\n",
    "    df[\"time_in_space_D\"] = df[\"time_in_space\"] / pd.Timedelta(days=1) # df[\"time_in_space_D\"] = df[\"time_in_space\"].astype(\"timedelta64[D]\")\n",
    "    df[\"alive\"] = df[\"date_of_death\"].apply(is_alive)\n",
    "    df[\"age\"] = df[\"birthdate\"].apply(calculate_age)\n",
    "    df[\"died_with_age\"] = df.apply(died_with_age, axis=1)\n",
    "    return df\n",
    "\n",
    "def is_alive(date_of_death):\n",
    "    if pd.isnull(date_of_death):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def rename_columns(df):\n",
    "    \"\"\"\n",
    "    The original column naming in the data set is not useful\n",
    "    for programming with pandas. So we rename it.\n",
    "    \"\"\"\n",
    "\n",
    "    name_mapping = {\n",
    "        \"astronaut\": \"astronaut_id\",\n",
    "        \"astronautLabel\": \"name\",\n",
    "        \"birthplaceLabel\": \"birthplace\",\n",
    "        \"sex_or_genderLabel\": \"sex_or_gender\",\n",
    "    }\n",
    "    df = df.rename(index=str, columns=name_mapping)\n",
    "    return df\n",
    "\n",
    "\n",
    "def died_with_age(row):\n",
    "    if pd.isnull(row[\"date_of_death\"]):\n",
    "        return None\n",
    "    born = row[\"birthdate\"]\n",
    "    today = row[\"date_of_death\"]\n",
    "    return today.year - born.year - ((today.month, today.day) < (born.month, born.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.composite\n",
    "def astronaut_data(draw):\n",
    "    astronaut = draw(st.from_regex(r\"http://www\\.wikidata\\.org/entity/Q\\d+\", fullmatch=True))\n",
    "    astronautLabel = draw(st.from_regex(r\"[A-Z][a-z]+ [A-Z][a-z]+\", fullmatch=True))\n",
    "    birthdate = draw(st.dates(min_value=date(1920, 1, 1), \n",
    "                                max_value=date(2030, 12, 31))\n",
    "                        )\n",
    "    birthplaceLabel = draw(st.from_regex(r\"[A-Z][a-z]+\", fullmatch=True))\n",
    "    sex_or_genderLabel = draw(st.sampled_from([\"male\", \"female\"]))\n",
    "    time_in_space = draw(st.integers(min_value=1, max_value=900)) \n",
    "    date_of_death = draw(st.one_of(\n",
    "        st.none(), \n",
    "        st.dates(birthdate + timedelta(days=1), \n",
    "                 max_value=date(2030, 12, 31))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    birthdate_str = birthdate.strftime(\"%Y-%m-%dT00:00:00Z\")\n",
    "    date_of_death_str = date_of_death.strftime(\"%Y-%m-%dT00:00:00Z\") if date_of_death else None\n",
    "\n",
    "    return {\n",
    "        \"astronaut\": astronaut,\n",
    "        \"astronautLabel\": astronautLabel,\n",
    "        \"birthdate\": birthdate_str,\n",
    "        \"birthplaceLabel\": birthplaceLabel,\n",
    "        \"sex_or_genderLabel\": sex_or_genderLabel,\n",
    "        \"time_in_space\": time_in_space,\n",
    "        \"date_of_death\": date_of_death_str\n",
    "    }\n",
    "\n",
    "@given(st.lists(astronaut_data(), min_size=1))\n",
    "def test_prepare_data_set(data):\n",
    "    df = DataFrame(data)\n",
    "    prepared_df = prepare_data_set(df)\n",
    "    assert 'age' in prepared_df.columns\n",
    "    assert 'alive' in prepared_df.columns\n",
    "    assert 'died_with_age' in prepared_df.columns\n",
    "    assert 'time_in_space_D' in prepared_df.columns\n",
    "\n",
    "test_prepare_data_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above might seem complex at first glance, the idea is intuitive. The function `prepare_data_set()` is given a variety of different inputs in order to the test the function is robust. The function `astronaut_data()` defines the properties of that will be used. These match the properties that are in the json file that the script uses.\n",
    "\n",
    "Seeing as data preparation is a very important - yet often times error prone - task in the data analysis process, this is a good example of how hypothesis can be used to help ensure a more robust data analysis script that is capable of processing multiple data types."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
